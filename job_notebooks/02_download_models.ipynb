{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b81cd21-97d4-41d0-be62-d9a2c01a6216",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Get Job Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19192187-4261-4c05-b55a-bd4a239f950e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params = dbutils.widgets.getAll()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72c9b7ac-176f-4110-9e2a-0707ad9f10a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Set catalog and schema\n",
    "\n",
    "We set the catalog and schema to organise our data and ensure it is stored in the correct location. Change these to suit your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa314426-4084-4f7e-ab1d-75d8e6c88f3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = params[\"catalog\"]\n",
    "schema = params[\"schema\"]\n",
    "transcription_model_id = params[\"transcription_model_id\"]\n",
    "transcription_model_save_path = f\"/Volumes/{catalog}/{schema}/data/models/llm_classifier/{transcription_model_id.replace(\"-\", \"_\").replace(\"/\", \"_\")}\"\n",
    "llm_model_id = params[\"llm_model_id\"]\n",
    "llm_model_save_path = f\"/Volumes/{catalog}/{schema}/data/models/llm_classifier/{llm_model_id.replace(\"-\", \"_\").replace(\"/\", \"_\")}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07cb67e9-fc0b-4257-a566-6e1cda524824",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create catalog, schema and volume if they don't exist, and create directories for compressed, raw audio files and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7daea3a-e6bc-40ed-88fe-dcc08ace9b88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.{schema}\")\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {catalog}.{schema}.data\")\n",
    "dbutils.fs.mkdirs(f\"/Volumes/{catalog}/{schema}/data/compressed/LJSpeech\")\n",
    "dbutils.fs.mkdirs(f\"/Volumes/{catalog}/{schema}/data/raw_audio/LJSpeech\")\n",
    "dbutils.fs.mkdirs(f\"/Volumes/{catalog}/{schema}/data/models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c68635b5-808e-4aa0-90f3-f74f544b6715",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Download models from Hugging Face\n",
    "\n",
    "We download two models from Hugging Face. We do this because it's more efficient to download these larger models once and retrieve them from storage for every batch of inference:\n",
    "- [Whisper-medium](https://huggingface.co/openai/whisper-medium)\n",
    "- [Phi-4](https://huggingface.co/microsoft/phi-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7e19328-33ba-479e-95b0-45c9604342f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48195079-5ad7-45f0-878b-44aa9cf1dde0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Whisper-medium is a state-of-the-art automatic speech recognition (ASR) model developed by OpenAI. It is designed to transcribe spoken language into written text with high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a388ea2a-6e89-454a-a5ae-a205dd9a811d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists(transcription_model_save_path):\n",
    "    dbutils.fs.rm(transcription_model_save_path, recurse=True)\n",
    "\n",
    "dbutils.fs.mkdirs(transcription_model_save_path)\n",
    "\n",
    "transcription_pipeline = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=transcription_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device=\"cuda:0\"\n",
    ")\n",
    "\n",
    "transcription_pipeline.save_pretrained(transcription_model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95d50414-8c4c-4630-afd0-7d36e355aad3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Phi-4 is a state-of-the-art language model developed by Microsoft. It is designed for text generation and can be used for various natural language processing tasks. We will use it for simple classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3592b4b1-a628-46ca-93a5-7f898e61db16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists(llm_model_save_path):\n",
    "    dbutils.fs.rm(llm_model_save_path, recurse=True)\n",
    "\n",
    "dbutils.fs.mkdirs(llm_model_save_path)\n",
    "\n",
    "llm_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=llm_model_id,\n",
    "    model_kwargs={\"torch_dtype\": \"auto\"},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "llm_pipeline.save_pretrained(llm_model_save_path)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02_download_models",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
