{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set catalog and schema\n",
    "\n",
    "We set the catalog and schema to organise our data and ensure it is stored in the correct location. Change these to suit your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG = \"marcell\"\n",
    "SCHEMA = \"call_centre_processing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create catalog, schema and volume if they don't exist, and create directories for compressed, raw audio files and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{SCHEMA}\")\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {CATALOG}.{SCHEMA}.data\")\n",
    "dbutils.fs.mkdirs(f\"/Volumes/{CATALOG}/{SCHEMA}/data/compressed/LJSpeech\")\n",
    "dbutils.fs.mkdirs(f\"/Volumes/{CATALOG}/{SCHEMA}/data/raw_audio/LJSpeech\")\n",
    "dbutils.fs.mkdirs(f\"/Volumes/{CATALOG}/{SCHEMA}/data/models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download raw audio files\n",
    "\n",
    "We download the [LJSpeech dataset](https://paperswithcode.com/dataset/ljspeech) from the URL and unzip it to the raw audio directory. This is a collection of 13,100 short audio clips of a single speaker reading passages from 7 non-fiction books. The files are stored in a tar.bz2 archive, so we will first download it and then unzip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the LJSpeech dataset\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "url = \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\"\n",
    "target_file_path = f\"/Volumes/{CATALOG}/{SCHEMA}/data/compressed/LJSpeech/LJSpeech-1.1.tar.bz2\"\n",
    "urllib.request.urlretrieve(url, target_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unzipping can take quite some time (>1hr)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the LJSpeech dataset\n",
    "\n",
    "import zipfile\n",
    "\n",
    "extract_to_path = f\"/Volumes/{CATALOG}/{SCHEMA}/data/raw_audio/LJSpeech\"\n",
    "with zipfile.ZipFile(target_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create reference dataframe\n",
    "\n",
    "We create a reference dataframe that contains the file paths of the raw audio files. We will use this dataframe to parallelize the inference process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "df_file_reference = spark.createDataFrame(dbutils.fs.ls(f\"/Volumes/{CATALOG}/{SCHEMA}/data/raw_audio/LJSpeech/LJSpeech-1.1/wavs/\"))\\\n",
    "  .withColumn(\"file_path\", F.expr(\"substring(path, 6, length(path))\")) # remove the leading dbfs:/ from the path\n",
    "\n",
    "df_file_reference.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the dataframe to a Delta table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file_reference.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"{CATALOG}.{SCHEMA}.recording_file_reference\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
