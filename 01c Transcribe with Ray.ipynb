{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b484548d-b693-4380-8879-fd19541576cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e783bbc5-ff99-49c8-8fa5-5b682cf5056f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.util.spark import setup_ray_cluster, shutdown_ray_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19ce314d-5a8b-4513-a963-575d391dd62c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "num_cpu_cores_per_worker = 4 # total cpu's present in each node\n",
    "num_cpus_head_node = \t4\n",
    "num_gpu_per_worker = 1\n",
    "num_gpus_head_node = 1\n",
    "\n",
    "ray_conf = setup_ray_cluster(\n",
    "  min_worker_nodes=4,\n",
    "  max_worker_nodes=4,\n",
    "  num_cpus_head_node= num_cpus_head_node,\n",
    "  num_gpus_head_node= num_gpus_head_node,\n",
    "  num_cpus_per_node=num_cpu_cores_per_worker,\n",
    "  num_gpus_per_node=num_gpu_per_worker\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "546f6e26-ed3e-40dd-90ac-990b00dce4d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "import torch\n",
    "import whisper\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df31c6d6-fc81-4840-811f-6878d7805c93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class WhisperTranscription:\n",
    "    def __init__(self):\n",
    "        self.unverified_context = ssl._create_unverified_context()\n",
    "        DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        whisper_model_type ='medium'\n",
    "        self.transcribe_whisper_model = whisper.load_model(whisper_model_type, device=DEVICE)\n",
    "\n",
    "    def transcribe(self, audio_filename, whisper_model):\n",
    "        try:\n",
    "            transcription = whisper_model.transcribe(audio_filename)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            transcription = {\"language\": None, \"text\": None}\n",
    "        finally:\n",
    "            return transcription\n",
    "\n",
    "\n",
    "    def __call__(self, row) -> dict:\n",
    "        print(row)\n",
    "        filepath = row[\"file_path\"]\n",
    "        transcription = self.transcribe(filepath, self.transcribe_whisper_model)\n",
    "        # row['audio_transcription'] = transcription\n",
    "\n",
    "        return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cce29e1-3676-4239-a94c-5d9db89ebb56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@F.pandas_udf(T.StringType())\n",
    "def transcribe_udf(filepaths: pd.Series) -> pd.Series:\n",
    "    import ray\n",
    "    import ray.data\n",
    "\n",
    "    ray.init(ray_conf[1])\n",
    "\n",
    "    @ray.remote\n",
    "    def ray_data_task(ds = None):\n",
    "        ds = ray.data.from_pandas(pd.DataFrame(filepaths.to_list(),columns = ['file_path']))\n",
    "\n",
    "        preds = (\n",
    "          ds.repartition(filepaths.shape[0])\n",
    "          .map(\n",
    "              WhisperTranscription,\n",
    "              compute=ray.data.ActorPoolStrategy(min_size=1,max_size=100),\n",
    "              num_gpus=.5,\n",
    "          )\n",
    "        )\n",
    "\n",
    "        final_df = preds.to_pandas()\n",
    "\n",
    "        return final_df.iloc[:, 0]\n",
    "    \n",
    "    return ray.get(ray_data_task.remote(filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98a5686f-7159-4984-b1a6-5ba466cefa35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_file_reference = spark.table(\"marcell.call_centre_processing.recording_file_reference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eba4646e-d5c5-4fc0-a68d-d63d045d10b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_transcriptions = df_file_reference.withColumn(\"transcription\", transcribe_udf(F.col(\"file_path\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2ffb6f9-82a3-4383-bfbe-e2e2c124572b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_transcriptions.write.mode(\"overwrite\").saveAsTable(\"marcell.call_centre_processing.transcriptions\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "01c Transcribe with Ray",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
