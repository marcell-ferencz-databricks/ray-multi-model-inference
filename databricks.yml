# yaml-language-server: $schema=bundle_config_schema.json
bundle:
  name: ray-mult-model-inference

variables:
  target_catalog:
    type: string
    description: The target UC catalog name to download and write assets to
    default: main
  target_schema:
    type: string
    description: The target UC schema name to download and write assets to
    default: ray_multi_model_inference
  transcription_model_id:
    type: string
    description: The Hugging Face model ID to use for transcription
    default: openai/whisper-medium
  llm_model_id:
    type: string
    description: The Hugging Face model ID to use for LLM
    default: microsoft/phi-4

resources:
  jobs:
    ray_pipeline:
      name: Ray Multi-Model Inference Bundle
      tasks:
        - task_key: check_if_models_exist
          notebook_task:
            notebook_path: job_notebooks/00_check_if_models_exist
            source: GIT
        - task_key: download_data
          notebook_task:
            notebook_path: job_notebooks/01_download_data
            source: GIT
        - task_key: model_needs_downloading
          depends_on:
            - task_key: check_if_models_exist
          condition_task:
            op: EQUAL_TO
            left: "{{tasks.check_if_models_exist.values.model_needs_downloading}}"
            right: "true"
        - task_key: run_inference
          depends_on:
            - task_key: download_models
            - task_key: download_data
          notebook_task:
            notebook_path: job_notebooks/03_run_inference
            source: GIT
          job_cluster_key: run_inference_cluster
        - task_key: run_inference_no_model_download
          depends_on:
            - task_key: model_needs_downloading
              outcome: "false"
            - task_key: download_data
          notebook_task:
            notebook_path: job_notebooks/03_run_inference
            source: GIT
          job_cluster_key: run_inference_cluster
        - task_key: download_models
          depends_on:
            - task_key: model_needs_downloading
              outcome: "true"
          notebook_task:
            notebook_path: job_notebooks/02_download_models
            source: GIT
          job_cluster_key: download_models_cluster
      job_clusters:
        - job_cluster_key: run_inference_cluster
          new_cluster:
            cluster_name: ""
            spark_version: 15.4.x-gpu-ml-scala2.12
            spark_conf:
              spark.task.resource.gpu.amount: "0"
              spark.databricks.pyspark.dataFrameChunk.enabled: "true"
            azure_attributes:
              first_on_demand: 1
              availability: ON_DEMAND_AZURE
              spot_bid_max_price: -1
            node_type_id: Standard_NC24ads_A100_v4
            enable_elastic_disk: true
            data_security_mode: SINGLE_USER
            runtime_engine: STANDARD
            num_workers: 2
        - job_cluster_key: download_models_cluster
          new_cluster:
            cluster_name: ""
            spark_version: 15.4.x-cpu-ml-scala2.12
            spark_conf:
              spark.master: local[*, 4]
              spark.databricks.cluster.profile: singleNode
            azure_attributes:
              first_on_demand: 1
              availability: ON_DEMAND_AZURE
              spot_bid_max_price: -1
            node_type_id: Standard_D16ads_v5
            driver_node_type_id: Standard_D16ads_v5
            custom_tags:
              ResourceClass: SingleNode
            enable_elastic_disk: true
            data_security_mode: SINGLE_USER
            runtime_engine: STANDARD
            num_workers: 0
      git_source:
        git_url: https://github.com/marcell-ferencz-databricks/ray-multi-model-inference.git
        git_provider: gitHub
        git_branch: main
      queue:
        enabled: true
      parameters:
        - name: catalog
          default: ${var.target_catalog}
        - name: schema
          default: ${var.target_schema}
        - name: transcription_model_id
          default: ${var.transcription_model_id}
        - name: llm_model_id
          default: ${var.llm_model_id}

targets:
  azure:
    default: true
      